# -Speaking-Disorder-Detection-Using-Convolutional-Neural-Networks

Project Title: 
 Detection of Dysarthria Using Convolutional Neural Network and Audio Feature Extraction
Description:
 In this project, I developed a machine learning model to detect dysarthria, a motor speech
 disorder, using audio feature extraction techniques and a Convolutional Neural Network (CNN).
 The project involved several key steps:
Data Collection and Preprocessing:
 Gathered audio data from individuals with and without dysarthria.
 Extracted multiple audio features including MFCCs, Chroma, Spectral Contrast, Tonnetz, and
 Zero-Crossing Rate using the Librosa library.
 Feature Engineering:
 Combined and normalized these features to create a comprehensive feature set for each audio
 sample.
 Ensured consistency and balance in the dataset for effective model training.
Model Development:
 Designed a CNN architecture with layers optimized for audio classification.
 Trained the model using a well-defined training and validation split to ensure robust
 performance.
Evaluation and Testing:
 Evaluated the model's performance using accuracy metrics.
 Tested the model on unseen data to validate its predictive capabilities.
Deployment:
 Implemented a prediction pipeline to classify new audio samples from a testing dataset.
 Saved the trained model and preprocessing parameters for future use.
 Technologies Used:
 Python
 Librosa for audio processing
 TensorFlow and Keras for building and training the CNN
 Pandas and NumPy for data manipulation and feature engineering
 
 
 This project demonstrates my ability to handle end-to-end machine learning workflows, from
 data preprocessing to model deployment, and highlights my skills in audio signal processing
 and deep learning
